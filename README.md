# AWS-Data---Engineering-Project-
1ï¸âƒ£ Data Ingestion: ğŸ“Š
             What I Did: Started with a Spotify dataset from Kaggle, split it into
             3 CSV files, and uploaded them to S3. 

2ï¸âƒ£ Data Transformation: ğŸ”„
             What I Did: Created a visual ETL pipeline in AWS Glue to clean and
             transform the data. 
Optimizations:ğŸš€
          Partitioning Data: Enhanced query performance.
          Efficient Formats: Switched to Parquet for speedier operations.
          Glue Job Tuning: Adjusted configurations to optimize performance 
          and cost.
          Script Efficiency: Refined PySpark code for better results.

ğŸŒŸ Achievements:
             30% Reduction in data processing time during transformation! 
             Achieved this by optimizing Glue scripts and applying best practices.

3ï¸âƒ£ Data Storage: ğŸ—ï¸
             What I Did: Stored the processed data back in S3, serving as my data
             warehouse. 

4ï¸âƒ£ Data Analysis: ğŸ“ˆ
            What I Did: Queried the processed data using AWS Athena. 
            Discover Queries: Check out this example query and its results!
            Attaching a snapshot of the Athena query editor with sample results 
            below.
